hamza@edge:~/Projet_Infra_Cloud/ansible/playbooks$ ansible-playbook -i ../inventory/inventory.ini 10-spark.yml 

source /etc/profile.d/spark.sh
spark-submit --version


Copier le fichier sur slave-1 et slave-2 au même chemin :
scp filesample.txt hamza@10.0.32.7:/tmp/filesample.txt
scp filesample.txt hamza@10.0.32.6:/tmp/filesample.txt



Lancer en local sur l'edge pour vérifier :
  spark-submit \
  --class WordCount \
  --master local[*] \
  wc.jar \
  file:///tmp/filesample.txt \
  /tmp/wc-output-local

  rm -rf /tmp/wc-output-1 ( sinon spark refuse d'écrire dessus si il existe déjà )


regarder les workers depuis pc personel : 

gcloud compute ssh edge \
  --zone us-central1-a \
  --project projet-cloud-n7 \
  --tunnel-through-iap \
  -- -L 8080:10.0.32.5:8080

ouvrir depuis pc perso : http://localhost:8080


submit bucket :
spark-submit \
  --class WordCount \
  --master spark://10.0.32.5:7077 \
  --packages com.google.cloud.bigdataoss:gcs-connector:hadoop3-2.2.19 \
  --conf spark.driver.userClassPathFirst=true \
  --conf spark.executor.userClassPathFirst=true \
  --conf spark.hadoop.fs.gs.impl=com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystem \
  --conf spark.hadoop.fs.AbstractFileSystem.gs.impl=com.google.cloud.hadoop.fs.gcs.GoogleHadoopFS \
  wc.jar \
  gs://projet-cloud-n7-spark/filesample.txt \
  gs://projet-cloud-n7-spark/wc-output-1




